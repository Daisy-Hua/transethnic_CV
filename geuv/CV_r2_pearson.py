import sys
sys.path.append('code/transethnic_prs-main/')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import transethnic_prs.model1.Model1Blk as model1blk
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from scipy.stats import spearmanr

gene = sys.argv[1]
gene_name = sys.argv[2]

pheno_total = pd.read_csv('data/GD462.GeneQuantRPKM.50FN.samplename.resk10.txt', sep = '\t', index_col = 'TargetID')
target_pheno_total = pheno_total.loc[gene]

eur_sample = pd.read_csv('data/clean/'+gene_name+'_genotype/eur_'+gene_name+'_genotype.012.indv', sep = '\t', header = None)
afr_sample = pd.read_csv('data/clean/'+gene_name+'_genotype/afr_'+gene_name+'_genotype.012.indv', sep = '\t',header = None)

target_pheno_eur = pd.merge(target_pheno_total, eur_sample, left_index = True, right_on = 0)
target_pheno_afr = pd.merge(target_pheno_total, afr_sample, left_index = True, right_on = 0)

eur_genotype = pd.read_csv('data/clean/'+gene_name+'_genotype/eur_'+gene_name+'_genotype.012', sep = '\t', header = None, index_col = 0)
afr_genotype = pd.read_csv('data/clean/'+gene_name+'_genotype/afr_'+gene_name+'_genotype.012', sep = '\t', header = None, index_col = 0)

pa = target_pheno_afr.set_index(0)
pe = target_pheno_eur.set_index(0)

#make sure the genotype matrix's order is the same as that of phenotype vector
sorted_eur_pheno = pd.merge(eur_sample, pe, left_on = 0 , right_index = True, how = 'left')
sorted_afr_pheno = pd.merge(afr_sample, pa, left_on = 0 , right_index = True, how = 'left')

#original matrix(before standardization)
X1o = np.array(eur_genotype,dtype = np.float64,order = 'C')
X2o = np.array(afr_genotype,dtype = np.float64,order = 'C')
y1o = np.array(sorted_eur_pheno[gene],dtype = np.float64,order = 'C')
y2o = np.array(sorted_afr_pheno[gene],dtype = np.float64,order = 'C')

def SNP_var_check(X):
    col_valid = []
    count = 0
    for col,x in enumerate(np.std(X, axis = 0)):
        if x==0:
            count +=1
        else:
            col_valid.append(col)
    return col_valid, count

def standardization(x):
    x=np.array(x,dtype = np.float64,order = 'C')
    x_center = x - np.mean(x,axis = 0)
    return x_center/np.std(x, axis = 0)


# step1:find invalid SNPs in original afr matrix and get 1st filtered SNP set on unsplit whole set.
col_valid1,count1=SNP_var_check(X2o)

# step2:split 1st filtered X2o into training set and test set
X_train,X_test,y_train,y_test = train_test_split(X2o,y2o,test_size = 0.2, random_state = 9,shuffle = False)

# step3: find invalid SNPs in test set and filter them out and get 2nd filtered SNP set on test set.
col_valid2,count2 = SNP_var_check(X_test)

# step4: KFold = 5
kf = KFold(n_splits=5)#without shuffling, the random state is immutable

# step5: pre-CV to find intersection of valid SNPs and get 3nd filtered SNP set on training set.
i = 1
for train_index, test_index in kf.split(X_train):
    train_index = list(train_index)
    test_index = list(test_index)
    X_to,X_vo = X_train[train_index,:],X_train[test_index,:]
    y_to, y_vo = y_train[train_index],y_train[test_index]
    col_valid_train,count_train = SNP_var_check(X_to)
    col_valid_valid,count_valid = SNP_var_check(X_vo)
    col_valid3 = list(set(col_valid_train).intersection(set(col_valid_valid)))
    globals()['col_set%s' % i] = col_valid3
    i+=1

valid_col_trainset = list(set(col_set1).intersection(col_set2).intersection(col_set3).intersection(col_set4).intersection(col_set5))

# step6: produce final valid SNPs on intersections generated by trainging sets, validation sets, and test,set.
col_valid_final = list(set(col_valid1).intersection(col_valid2).intersection(valid_col_trainset))

# choose the valid subset of EUR matrix, standardize it and generate summary statistics.
X1o = X1o[:, col_valid_final]
X1, y1 = standardization(X1o), standardization(y1o)
A1 = X1.T @ X1
b1 = X1.T @ y1

# choose the valid subset of AFR test set, standardize it.
X_test = X_test[:, col_valid_final]
X_test_std = standardization(X_test)
y_test_std = standardization(y_test)
X_train_1pop = X_train[:, col_valid_final]

def test(y_hat_test):
    # validate the final result on AFR test set.
    y_hat_test = (y_hat_test-y_hat_test.mean())/y_hat_test.std()
    correlation_test_matrix = np.corrcoef(y_hat_test, y_test_std)
    correlation_test = correlation_test_matrix[0,1]
    r2 = correlation_test**2
    m, b = np.polyfit(y_test_std, y_hat_test, 1)
    sp_r, _ = spearmanr(y_hat_test,y_test_std)
    return r2,m,sp_r**2,sp_r


# official CV for hyperparameter lambda and estimator beta_hat
Max1 = 0
for train_index, test_index in kf.split(X_train):
    X_to, X_vo = X_train[:,col_valid_final][train_index,:], X_train[:,col_valid_final][test_index,:]
    y_to, y_vo = y_train[train_index], y_train[test_index]
    X_t_std, X_v_std, y_t_std, y_v_std = standardization(X_to), standardization(X_vo), standardization(y_to), standardization(y_vo)
    mod = model1blk.Model1Blk([A1],[b1],[X_t_std],y_t_std)
    beta_mat_en, lambda_seq_en, niters_en, tols_en, convs_en = mod.solve_path(alpha=0.1)
    Max2 = 0
    for i in range(100):
        beta_hat = beta_mat_en[:,i]
        y_v_hat = X_v_std @ beta_hat
        correlation_matrix = np.corrcoef(y_v_hat, y_v_std)
        correlation_yvhat_yv = correlation_matrix[0,1]
        r2 = correlation_yvhat_yv**2
        if r2>Max2:
            Max2=r2
            idx = i
    if Max2>Max1:
        Max1=Max2
        lam=lambda_seq_en[idx]
        beta_h=beta_mat_en[:,idx]

y_hat_test_2pop= X_test_std @ beta_h
r2_2pop, m_2pop, spr2_2pop, spr_2pop = test(y_hat_test_2pop)

# AFR only EN model
from sklearn.linear_model import ElasticNetCV
model = ElasticNetCV(l1_ratio=0.1, alphas=np.arange(1e-5,4000,0.1), cv=kf, n_jobs=-1)
model.fit(X_train_1pop, y_train)
y_hat_test_1pop = model.predict(X_test_std)
r2_1pop, m_1pop, spr2_1pop, spr_1pop = test(y_hat_test_1pop)

print(gene,'\t',r2_2pop,'\t',m_2pop,'\t',spr2_2pop,'\t',spr_2pop,'\t',r2_1pop,'\t',m_1pop,'\t',spr2_1pop,'\t',spr_1pop)

